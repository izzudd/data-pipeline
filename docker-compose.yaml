version: '3.8'

name: de

services:
  # lake
  hadoop-master:
    build: ./hadoop
    image: hadoop-image
    container_name: hadoop-master
    entrypoint: ["./entrypoint.sh", "master"]
    hostname: hadoop-master
    ports:
      - 8080:9870
      - 8088:8088
      # - 2002:22
    depends_on:
      - hadoop-worker
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
    environment:
      - HDFS_REPLICATION_FACTOR=${HDFS_REPLICATION:-1}
      - HDFS_WORKER_PREFIX=de-hadoop-worker-
      - HDFS_WORKER_COUNT=${HDFS_WORKER_COUNT:-1}
      - HDFS_START_YARN=${HDFS_START_YARN}
    volumes:
      - ./hadoop/config:/root/config:ro
      - ./hadoop/data:/root/data:ro
      - ./hadoop/example:/root/example:ro

  hadoop-worker:
    image: hadoop-image
    entrypoint: ["./entrypoint.sh", "worker"]
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 1G
    environment:
      - HDFS_REPLICATION_FACTOR=${HDFS_REPLICATION:-1}
      - HDFS_WORKER_PREFIX=de-hadoop-worker-
      - HDFS_WORKER_COUNT=${HDFS_WORKER_COUNT:-1}
    volumes:
      - ./hadoop/config:/root/config:ro

  # worker
  # spark-master:
  #   build: ./spark
  #   image: spark-image
  #   container_name: spark-master
  #   entrypoint: ['./entrypoint.sh', 'master']
  #   hostname: spark-master
  #   depends_on:
  #     - hadoop-master
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 512M
  #   volumes:
  #     - ./data/spark-data:/opt/spark/data
  #     - ./data/spark-apps:/opt/spark/apps
  #     - ./data/spark-logs:/opt/spark/spark-events
  #     - ./spark/config:/opt/spark/conf:ro
  #     - ./spark/app:/root/app:ro
  #   environment:
  #     - SPARK_NO_DAEMONIZE=true
  #   ports:
  #     - 8081:8080
  #     - 7077:7077
  #     # - 2001:22

  # spark-worker:
  #   image: spark-image
  #   entrypoint: ['./entrypoint.sh', 'worker']
  #   depends_on:
  #     - spark-master
  #   deploy:
  #     replicas: ${SPARK_WORKER_COUNT:-1}
  #     resources:
  #       limits:
  #         cpus: '2'
  #         memory: 1G
  #   environment:
  #     - SPARK_NO_DAEMONIZE=true
  #   volumes:
  #     - ./data/spark-data:/opt/spark/data
  #     - ./data/spark-apps:/opt/spark/apps
  #     - ./data/spark-logs:/opt/spark/spark-events
  #     - ./spark/config:/opt/spark/conf:ro

  # warehouse
  # db:
  #   image: postgres:alpine
  #   shm_size: 128M
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 512M
  #   environment:
  #     POSTGRES_USER: user
  #     POSTGRES_PASSWORD: password
  #   volumes:
  #     - ./data/postgres-data:/var/lib/postgresql/data
  
  # adminer:
  #   image: adminer:latest
  #   depends_on:
  #     - db
  #   ports:
  #     - 8080:8080
